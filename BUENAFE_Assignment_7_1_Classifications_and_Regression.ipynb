{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "BUENAFE, Lorenz Angelo N. <br>\n",
        "1915058 <br>\n",
        "CPE 019 - CPE32S9 <br>"
      ],
      "metadata": {
        "id": "dIbVdJmaD2V3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose any dataset applicable to the classification problem, and also, choose any dataset applicable to the regression problem."
      ],
      "metadata": {
        "id": "J0Y05vcKECmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification - https://www.kaggle.com/datasets/bharath011/heart-disease-classification-dataset <br>\n",
        "\n",
        "Regression - https://www.kaggle.com/datasets/anubhavgoyal10/laptop-prices-dataset\n"
      ],
      "metadata": {
        "id": "ATLLAymTa3x9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain your datasets and the problem being addressed."
      ],
      "metadata": {
        "id": "lFBeQnrmEF7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/bharath011/heart-disease-classification-dataset <br>\n",
        "The main purpose here is to collect characteristics of Heart Attack or factors that contribute to it. <br>\n",
        "\n",
        "https://www.kaggle.com/datasets/anubhavgoyal10/laptop-prices-dataset <br>\n",
        "This dataset can be used for regression analysis to predict the prices of laptops based on their features."
      ],
      "metadata": {
        "id": "xKmm0nb9ad35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For classification, do the following: <br>\n",
        "Create a base model <br>\n",
        "Evaluate the model with k-fold cross validation <br>\n",
        "Improve the accuracy of your model by applying additional hidden layers\n"
      ],
      "metadata": {
        "id": "gjdFnuU-ELHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Creating a base model"
      ],
      "metadata": {
        "id": "nllbT5A3aERK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "rbNI8GjOaD9j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZBMuU4zQDyIT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/CPE 019 Emerging Technologies 3/Assignment 7.1/Heart Attack.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R3U8Sfrtmblj",
        "outputId": "820bb258-1024-4643-cfe9-ea3972e64e6b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of       age  gender  impluse  pressurehight  pressurelow  glucose    kcm  \\\n",
            "0      64       1       66            160           83    160.0   1.80   \n",
            "1      21       1       94             98           46    296.0   6.75   \n",
            "2      55       1       64            160           77    270.0   1.99   \n",
            "3      64       1       70            120           55    270.0  13.87   \n",
            "4      55       1       64            112           65    300.0   1.08   \n",
            "...   ...     ...      ...            ...          ...      ...    ...   \n",
            "1314   44       1       94            122           67    204.0   1.63   \n",
            "1315   66       1       84            125           55    149.0   1.33   \n",
            "1316   45       1       85            168          104     96.0   1.24   \n",
            "1317   54       1       58            117           68    443.0   5.80   \n",
            "1318   51       1       94            157           79    134.0  50.89   \n",
            "\n",
            "      troponin     class  \n",
            "0        0.012  negative  \n",
            "1        1.060  positive  \n",
            "2        0.003  negative  \n",
            "3        0.122  positive  \n",
            "4        0.003  negative  \n",
            "...        ...       ...  \n",
            "1314     0.006  negative  \n",
            "1315     0.172  positive  \n",
            "1316     4.250  positive  \n",
            "1317     0.359  positive  \n",
            "1318     1.770  positive  \n",
            "\n",
            "[1319 rows x 9 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 0:4].values\n",
        "y = df.iloc[:, 4].values"
      ],
      "metadata": {
        "id": "vJ2PWiqLe8n2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qhCDn_rue_om"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "-QTOICbXfC6E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50,), activation='relu', alpha=0.0001, batch_size=256, learning_rate_init=0.001, max_iter=500)\n",
        "mlp_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "9RzlPnhUfD9Q",
        "outputId": "47c1bb98-87af-4221-bd17-7e3f410a6367"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(batch_size=256, hidden_layer_sizes=(50,), max_iter=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(batch_size=256, hidden_layer_sizes=(50,), max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(batch_size=256, hidden_layer_sizes=(50,), max_iter=500)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Evaluate the model with k-fold cross validation:"
      ],
      "metadata": {
        "id": "Yp60cBLmfTO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold = 10\n",
        "accuracies = cross_val_score(estimator=mlp_classifier, X=X_train, y=y_train, cv=k_fold)\n",
        "\n",
        "print(f\"Accuracy: {accuracies.mean()*100:.2f}% ({accuracies.std()*100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QfltqWGhfOkt",
        "outputId": "530acc36-bf57-4318-c875-2fba15aa8cc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 7.67% (2.28%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Improve the accuracy of your model by applying additional hidden layers:"
      ],
      "metadata": {
        "id": "SWbkWCx1fmku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(50, 50, 50), activation='relu', alpha=0.0001, batch_size=256, learning_rate_init=0.001, max_iter=500)\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\")\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-BwnONghfrA1",
        "outputId": "bfd8d50a-e6ce-43c8-98a1-7ca4303eb48d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          38       0.00      0.00      0.00         0\n",
            "          41       0.00      0.00      0.00         0\n",
            "          42       1.00      1.00      1.00         1\n",
            "          44       0.00      0.00      0.00         0\n",
            "          45       0.00      0.00      0.00         1\n",
            "          48       0.25      0.25      0.25         4\n",
            "          49       0.00      0.00      0.00         2\n",
            "          50       0.00      0.00      0.00         2\n",
            "          51       0.00      0.00      0.00         3\n",
            "          52       0.00      0.00      0.00         4\n",
            "          53       0.00      0.00      0.00         3\n",
            "          54       0.00      0.00      0.00         4\n",
            "          55       0.00      0.00      0.00         7\n",
            "          56       0.00      0.00      0.00         3\n",
            "          57       0.25      0.14      0.18         7\n",
            "          58       0.00      0.00      0.00         6\n",
            "          59       0.00      0.00      0.00         2\n",
            "          60       0.03      0.25      0.05         4\n",
            "          61       0.00      0.00      0.00        10\n",
            "          62       0.00      0.00      0.00         4\n",
            "          63       0.10      0.33      0.15         3\n",
            "          64       1.00      0.09      0.17        11\n",
            "          65       0.00      0.00      0.00         7\n",
            "          66       0.00      0.00      0.00         1\n",
            "          67       0.00      0.00      0.00         3\n",
            "          68       0.14      0.07      0.09        15\n",
            "          69       0.00      0.00      0.00        10\n",
            "          70       0.11      0.09      0.10        11\n",
            "          71       0.00      0.00      0.00         5\n",
            "          72       0.50      0.20      0.29         5\n",
            "          73       0.00      0.00      0.00         2\n",
            "          74       0.00      0.00      0.00         5\n",
            "          75       0.29      0.28      0.29        18\n",
            "          76       0.00      0.00      0.00        11\n",
            "          77       0.33      0.33      0.33         3\n",
            "          78       0.00      0.00      0.00         5\n",
            "          79       0.00      0.00      0.00        11\n",
            "          80       0.29      0.44      0.35         9\n",
            "          81       0.17      0.12      0.14         8\n",
            "          82       0.00      0.00      0.00         6\n",
            "          83       0.00      0.00      0.00         4\n",
            "          84       0.00      0.00      0.00         3\n",
            "          85       0.00      0.00      0.00         7\n",
            "          86       0.00      0.00      0.00         3\n",
            "          87       0.00      0.00      0.00         2\n",
            "          88       0.00      0.00      0.00         5\n",
            "          89       0.00      0.00      0.00         3\n",
            "          90       0.25      0.33      0.29         3\n",
            "          91       0.00      0.00      0.00         1\n",
            "          93       0.00      0.00      0.00         1\n",
            "          94       0.00      0.00      0.00         2\n",
            "          95       0.12      0.25      0.17         4\n",
            "          97       0.00      0.00      0.00         0\n",
            "          98       0.00      0.00      0.00         0\n",
            "          99       0.00      0.00      0.00         1\n",
            "         104       0.33      1.00      0.50         2\n",
            "         105       0.00      0.00      0.00         3\n",
            "         109       0.00      0.00      0.00         1\n",
            "         110       0.00      0.00      0.00         0\n",
            "         118       0.00      0.00      0.00         2\n",
            "         128       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.09       264\n",
            "   macro avg       0.10      0.10      0.09       264\n",
            "weighted avg       0.13      0.09      0.09       264\n",
            "\n",
            "\n",
            "Accuracy Score:\n",
            "0.0946969696969697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For regression, do the following: <br>\n",
        "Create a base model <br>\n",
        "Improve the model by standardizing the dataset <br>\n",
        "Show tuning of layers and neurons (see evaluating small and larger networks)"
      ],
      "metadata": {
        "id": "41_ajZHbgATt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Creating a base model"
      ],
      "metadata": {
        "id": "FKkbfFeggFhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "EDbfVFoetWd5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/CPE 019 Emerging Technologies 3/Assignment 7.1/laptopPrice.csv')"
      ],
      "metadata": {
        "id": "LK9gjC0WtYCK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unnecessary columns\n",
        "df = df.drop(['rating', 'Number of Ratings', 'Number of Reviews'], axis=1)\n",
        "\n",
        "# Convert categorical variables to numerical using one-hot encoding\n",
        "df = pd.get_dummies(df)\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = df.drop('Price', axis=1)\n",
        "y = df['Price']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "fxVZ5zKqtatO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9qPy_Wjetb7l",
        "outputId": "e30581b9-226c-4b78-a14e-36814bf24377"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 1s 2ms/step - loss: 7909235200.0000\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7908779520.0000\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7907524608.0000\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7904487936.0000\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7898453504.0000\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7888128000.0000\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7872027136.0000\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7849320448.0000\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7818050560.0000\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7778030592.0000\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7727673856.0000\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7665488896.0000\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7592023552.0000\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7504596480.0000\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7404532736.0000\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7289305088.0000\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7159079424.0000\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7015971840.0000\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6858405888.0000\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 6685970944.0000\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6502671360.0000\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 6307851776.0000\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6101081088.0000\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5886175744.0000\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5663219712.0000\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5435048448.0000\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5198081024.0000\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 4964520448.0000\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 4726394368.0000\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 4491283456.0000\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 4259766272.0000\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 4035402496.0000\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 3819402240.0000\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 3611685888.0000\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 3417762560.0000\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 3236983552.0000\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 3066659328.0000\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2912227328.0000\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2776074240.0000\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 2651009792.0000\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2543217664.0000\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2445088512.0000\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2360356352.0000\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2291592192.0000\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2228399616.0000\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 2174241792.0000\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2130108672.0000\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2090958208.0000\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2056573824.0000\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2025516800.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e9c1e17e9e0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the dataset\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create a new model\n",
        "model_scaled = Sequential()\n",
        "model_scaled.add(Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "model_scaled.add(Dense(32, activation='relu'))\n",
        "model_scaled.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile and train the model\n",
        "model_scaled.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model_scaled.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "syr5Zmz7td32",
        "outputId": "cefacdbe-b9be-4233-c3ac-7876deccd51e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 1s 2ms/step - loss: 7909236736.0000\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7908844032.0000\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7908256768.0000\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7907201024.0000\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7905420288.0000\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7902669312.0000\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7898300928.0000\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7892186112.0000\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7883592192.0000\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7872281600.0000\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7857424384.0000\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7839137280.0000\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7816539648.0000\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7789151744.0000\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7756845568.0000\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7719604736.0000\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7676214784.0000\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7628214272.0000\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7573004800.0000\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7511797760.0000\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7443623424.0000\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7369946112.0000\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 7288383488.0000\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7199558656.0000\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7106749952.0000\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 7005659648.0000\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6898659840.0000\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6786370560.0000\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6667321344.0000\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6540859904.0000\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6410493952.0000\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6277344256.0000\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 6130328064.0000\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5986698752.0000\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5835498496.0000\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5683389440.0000\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5524302336.0000\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5364847104.0000\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5202641920.0000\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 5037799424.0000\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 4871534592.0000\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 4706433536.0000\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 4538463232.0000\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 4374000128.0000\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 4210573568.0000\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 4049666304.0000\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 3890202624.0000\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 3735452672.0000\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 3584151040.0000\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 3439695360.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e9c0e4560e0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to create a model with variable number of layers and neurons\n",
        "def create_model(layers, neurons):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neurons[0], activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "\n",
        "    for i in range(1, layers):\n",
        "        model.add(Dense(neurons[i], activation='relu'))\n",
        "\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "# Define the parameters for tuning\n",
        "layers = [1, 2, 3]  # Number of hidden layers\n",
        "neurons = [32, 64, 128]  # Number of neurons in each layer\n",
        "\n",
        "# Perform grid search to find the best model\n",
        "best_model = None\n",
        "best_loss = float('inf')\n",
        "\n",
        "for layer in layers:\n",
        "    for neuron in neurons:\n",
        "        model_tuned = create_model(layer, [neuron] * layer)\n",
        "        model_tuned.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "        loss = model_tuned.evaluate(X_test_scaled, y_test)\n",
        "\n",
        "        if loss < best_loss:\n",
        "            best_loss = loss\n",
        "            best_model = model_tuned\n",
        "\n",
        "# Print the best model's architecture and loss\n",
        "print(\"Best model architecture:\")\n",
        "best_model.summary()\n",
        "print(\"Best model loss:\", best_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gFQNiXWttgfq",
        "outputId": "953167dc-552e-41d3-89e8-79b939a39bf1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 7910977536.0000\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 7841633280.0000\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 7691759104.0000\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 4316863488.0000\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 1712784384.0000\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1026023744.0000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 820184064.0000\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 717905728.0000\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 695052544.0000\n",
            "Best model architecture:\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_29 (Dense)            (None, 128)               9344      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42497 (166.00 KB)\n",
            "Trainable params: 42497 (166.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Best model loss: 695052544.0\n"
          ]
        }
      ]
    }
  ]
}